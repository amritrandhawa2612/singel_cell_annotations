{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4c6020-6396-4faa-aa4d-ec979a7e4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy==1.12\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gaiacronus\\.conda\\envs\\demo3\\lib\\site-packages (from sympy==1.12) (1.3.0)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.1/5.7 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.5/5.7 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 14.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "Successfully installed sympy-1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.7.0.dev20250113+cu126 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.12 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install sympy==1.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f407cc9f-40b2-4e72-8337-48d275eac2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/203.0 MB 5.6 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 2.1/203.0 MB 4.9 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.1/203.0 MB 5.0 MB/s eta 0:00:41\n",
      "    --------------------------------------- 4.5/203.0 MB 5.3 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 5.5/203.0 MB 5.4 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 6.6/203.0 MB 5.2 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 7.9/203.0 MB 5.5 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 9.4/203.0 MB 5.7 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 10.5/203.0 MB 5.7 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.3/203.0 MB 5.5 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 12.1/203.0 MB 5.4 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 12.8/203.0 MB 5.3 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 13.9/203.0 MB 5.2 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 14.9/203.0 MB 5.2 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 15.7/203.0 MB 5.1 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 17.0/203.0 MB 5.2 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 18.4/203.0 MB 5.2 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 19.7/203.0 MB 5.3 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 21.2/203.0 MB 5.5 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 22.8/203.0 MB 5.6 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 24.6/203.0 MB 5.7 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 26.2/203.0 MB 5.9 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 27.3/203.0 MB 5.8 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 28.0/203.0 MB 5.7 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 28.6/203.0 MB 5.6 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 29.4/203.0 MB 5.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 29.9/203.0 MB 5.4 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 30.4/203.0 MB 5.4 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 31.2/203.0 MB 5.3 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 31.7/203.0 MB 5.2 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 32.2/203.0 MB 5.1 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 33.0/203.0 MB 5.1 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 33.8/203.0 MB 5.0 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 34.6/203.0 MB 5.0 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 35.4/203.0 MB 5.0 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 36.4/203.0 MB 5.0 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 37.7/203.0 MB 5.0 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 39.1/203.0 MB 5.0 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 40.4/203.0 MB 5.1 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 42.2/203.0 MB 5.1 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 43.3/203.0 MB 5.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 44.6/203.0 MB 5.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 45.6/203.0 MB 5.2 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 46.4/203.0 MB 5.2 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 47.4/203.0 MB 5.2 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 48.2/203.0 MB 5.1 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 49.3/203.0 MB 5.1 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 50.1/203.0 MB 5.1 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 50.6/203.0 MB 5.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 51.4/203.0 MB 5.0 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 52.2/203.0 MB 5.0 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 53.2/203.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 54.0/203.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 54.8/203.0 MB 5.0 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 55.6/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 56.1/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 57.1/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 58.2/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 59.0/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 59.8/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 60.8/203.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 62.1/203.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------ --------------------------- 63.7/203.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------ --------------------------- 65.5/203.0 MB 5.0 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 67.4/203.0 MB 5.1 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 68.9/203.0 MB 5.1 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 70.3/203.0 MB 5.1 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 71.6/203.0 MB 5.2 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 72.6/203.0 MB 5.2 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 73.7/203.0 MB 5.2 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 75.0/203.0 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 76.3/203.0 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 77.3/203.0 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 78.1/203.0 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 78.9/203.0 MB 5.2 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 80.0/203.0 MB 5.2 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 80.7/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 81.3/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 82.1/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 83.1/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 83.9/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 85.2/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 86.0/203.0 MB 5.1 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 86.8/203.0 MB 5.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 87.6/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 88.6/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 89.1/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 89.9/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 90.7/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 91.5/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 92.3/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 93.3/203.0 MB 5.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 94.1/203.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 94.9/203.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 96.2/203.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 97.3/203.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 98.3/203.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 99.4/203.0 MB 5.0 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 100.7/203.0 MB 5.0 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 102.2/203.0 MB 5.0 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 104.1/203.0 MB 5.0 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 105.9/203.0 MB 5.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 107.7/203.0 MB 5.1 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 109.1/203.0 MB 5.1 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 110.4/203.0 MB 5.1 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 111.7/203.0 MB 5.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 113.0/203.0 MB 5.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 114.3/203.0 MB 5.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 115.9/203.0 MB 5.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 117.2/203.0 MB 5.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 118.5/203.0 MB 5.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 119.8/203.0 MB 5.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 121.4/203.0 MB 5.3 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 122.9/203.0 MB 5.3 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 124.5/203.0 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 125.8/203.0 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 127.1/203.0 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 128.7/203.0 MB 5.3 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 130.5/203.0 MB 5.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 132.6/203.0 MB 5.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 134.2/203.0 MB 5.4 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 135.8/203.0 MB 5.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 137.4/203.0 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 138.9/203.0 MB 5.5 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 140.2/203.0 MB 5.5 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 141.8/203.0 MB 5.5 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 143.1/203.0 MB 5.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 145.0/203.0 MB 5.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 146.8/203.0 MB 5.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 148.9/203.0 MB 5.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 150.5/203.0 MB 5.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 152.3/203.0 MB 5.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 154.1/203.0 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 156.2/203.0 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 158.3/203.0 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 159.6/203.0 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 161.5/203.0 MB 5.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 163.3/203.0 MB 5.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 164.4/203.0 MB 5.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 165.9/203.0 MB 5.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 167.5/203.0 MB 5.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 169.6/203.0 MB 5.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 171.7/203.0 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 173.0/203.0 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 174.3/203.0 MB 5.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 175.9/203.0 MB 5.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 177.2/203.0 MB 5.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 178.8/203.0 MB 5.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 180.9/203.0 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 182.7/203.0 MB 6.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.3/203.0 MB 6.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 185.9/203.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 187.4/203.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.7/203.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 190.1/203.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.1/203.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 192.4/203.0 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.0/203.0 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.8/203.0 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.4/203.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.7/203.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.3/203.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.9/203.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 6.1 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\gaiacronus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\gaiacronus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scgpt\n",
      "  Using cached scgpt-0.1.5-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting flash-attn<1.0.5\n",
      "  Using cached flash_attn-1.0.4.tar.gz (2.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [22 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\gaiacronus\\AppData\\Local\\Temp\\pip-install-43yljevc\\flash-attn_77605d91efbd4740a8193cf084675b72\\setup.py\", line 106, in <module>\n",
      "      raise_if_cuda_home_none(\"flash_attn\")\n",
      "    File \"C:\\Users\\gaiacronus\\AppData\\Local\\Temp\\pip-install-43yljevc\\flash-attn_77605d91efbd4740a8193cf084675b72\\setup.py\", line 53, in raise_if_cuda_home_none\n",
      "      raise RuntimeError(\n",
      "  RuntimeError: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "  \n",
      "  Warning: Torch did not find available GPUs on this system.\n",
      "   If your intention is to cross-compile, this is not an error.\n",
      "  By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "  Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "  and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "  If you wish to cross-compile for a single specific architecture,\n",
      "  export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "  \n",
      "  \n",
      "  \n",
      "  torch.__version__  = 2.5.1+cpu\n",
      "  \n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (0.19.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (2.20.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\gaiacronus\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch\n",
    "!pip install scgpt \"flash-attn<1.0.5\"\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2281ef0b-cb7f-4ed6-8309-84da0e6081bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\Users\\gaiacronus\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchtext, torchvision\n",
      "---\n",
      "Name: torchtext\n",
      "Version: 0.18.0\n",
      "Summary: Text utilities, models, transforms, and datasets for PyTorch.\n",
      "Home-page: https://github.com/pytorch/text\n",
      "Author: PyTorch Text Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD\n",
      "Location: C:\\Users\\gaiacronus\\.conda\\envs\\demo3\\Lib\\site-packages\n",
      "Requires: numpy, requests, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66469bc6-218c-4621-a843-3f999058cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaiacronus\\Downloads\\work\\combine\\scgpt\\model\\model.py:21: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "C:\\Users\\gaiacronus\\Downloads\\work\\combine\\scgpt\\model\\multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "C:\\Users\\gaiacronus\\.conda\\envs\\demo3\\Lib\\site-packages\\torchtext\\__init__.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\\n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \\n\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_SYMBOLIC_SHAPE_INFERENCE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscgpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize_and_pad\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscgpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pretrained_scGPT\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscgpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_for_training\n",
      "File \u001b[1;32m~\\Downloads\\work\\combine\\scgpt\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     handler\u001b[38;5;241m.\u001b[39msetFormatter(formatter)\n\u001b[0;32m     16\u001b[0m     logger\u001b[38;5;241m.\u001b[39maddHandler(handler)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model, tokenizer, scbank, utils, tasks\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollator\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubsetsBatchSampler\n",
      "File \u001b[1;32m~\\Downloads\\work\\combine\\scgpt\\tokenizer\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgene_tokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Downloads\\work\\combine\\scgpt\\tokenizer\\gene_tokenizer.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtorch_vocab\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocab\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# from transformers.tokenization_utils import PreTrainedTokenizer\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# from transformers import AutoTokenizer, BertTokenizer\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\demo3\\Lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\.conda\\envs\\demo3\\Lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m _init_extension()\n",
      "File \u001b[1;32m~\\.conda\\envs\\demo3\\Lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32m~\\.conda\\envs\\demo3\\Lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_ops.py:1350\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1345\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(path)\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32m~\\.conda\\envs\\demo3\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import TOSICA\n",
    "import os\n",
    "os.environ[\"PYTORCH_SYMBOLIC_SHAPE_INFERENCE\"] = \"0\"\n",
    "from scgpt.tokenizer import tokenize_and_pad\n",
    "from scgpt.model import load_pretrained_scGPT\n",
    "from scgpt.preprocess import prepare_for_training\n",
    "# Load the h_pancreas datasets\n",
    "train_path = \"C:/Users/gaiacronus/Downloads/work/combine/adata/hPancreas_train_adata.h5ad\"  # Training dataset\n",
    "test_path = \"C:/Users/gaiacronus/Downloads/work/combine/adata/hPancreas_test_adata.h5ad\"   # Testing dataset\n",
    "\n",
    "# Load the datasets as AnnData objects\n",
    "train_adata = sc.read_h5ad(train_path)\n",
    "test_adata = sc.read_h5ad(test_path)\n",
    "\n",
    "#  Preprocess the datasets\n",
    "# Align the gene names in both datasets\n",
    "common_genes = train_adata.var_names.intersection(test_adata.var_names)\n",
    "train_adata = train_adata[:, common_genes]\n",
    "test_adata = test_adata[:, common_genes]\n",
    "# Convert AnnData object to scGPT-compatible format\n",
    "train_scGPT = prepare_for_training(train_adata)\n",
    "test_scGPT = prepare_for_training(test_adata)\n",
    "# Normalize the data \n",
    "sc.pp.normalize_total(train_adata, target_sum=1e4)\n",
    "sc.pp.log1p(train_adata)\n",
    "\n",
    "sc.pp.normalize_total(test_adata, target_sum=1e4)\n",
    "sc.pp.log1p(test_adata)\n",
    "ref_adata=train_adata\n",
    "query_adata=test_adata\n",
    "label_key = \"Celltype2\"  \n",
    "gmt_path = \"C:/Users/gaiacronus/Downloads/work/combine/TOSICA/resources/immune.gmt\"  # Path to the gene set file \n",
    "project_name = \"tostry\"    \n",
    "\n",
    "# Train the model\n",
    "TOSICA.train(\n",
    "    ref_adata,\n",
    "    gmt_path=gmt_path,\n",
    "    project=project_name,\n",
    "    epochs=3,\n",
    "    label_name=label_key\n",
    ")\n",
    "\n",
    " #Predict cell types in the test dataset\n",
    "model_weight_path = f\"{project_name}/model_weight.h5\"\n",
    "\n",
    "# Loading pre-trained scGPT model and fine-tune \n",
    "model = load_pretrained_scGPT(best_model.pt)  \n",
    "#  Fine-tune the model using the training data\n",
    "model.train(train_scGPT, epochs=3, batch_size=32)\n",
    "\n",
    "# Predict cell types\n",
    "predicted_adata = TOSICA.pre(\n",
    "    query_adata,\n",
    "    model_weight_path=model_weight_path,\n",
    "    project=project_name\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_scGPT)\n",
    "test_adata.obs[\"scGPT_predictions\"] = predictions\n",
    " #Inspect the predictions\n",
    "# Predicted cell types and probabilities are added to the `obs` of the AnnData object\n",
    "print(predicted_adata.obs.head())  # Check the predicted labels and probabilities\n",
    "\n",
    "# Save the results for further analysis\n",
    "predicted_adata.write(\"h_pancreas_predicted.h5ad\")\n",
    "\n",
    "#  Compare TOSICA and scGPT results\n",
    "print(\"TOSICA Predictions:\\n\", predicted_adata.obs.head())\n",
    "print(\"scGPT Predictions:\\n\", test_adata.obs[\"scGPT_predictions\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c57fd-6952-4fce-8ccb-6acabb40e061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7bf84-2659-4ad0-9d52-89770067d064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
