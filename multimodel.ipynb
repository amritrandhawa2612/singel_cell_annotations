{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d896a8f-b4cd-4314-b1e1-d4bcac261c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tasks:\n",
      "1. Cell Type Annotation\n",
      "2. Protein Prediction\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the task (1 or 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "1. Dataset_A\n",
      "2. Dataset_B\n",
      "3. Dataset_C\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the dataset (1, 2, or 3):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pipeline for model: TOSICA\n",
      "Preprocessing dataset: Dataset_B for TOSICA\n",
      "Pretraining TOSICA with data: processed_Dataset_B_TOSICA\n",
      "Fine-tuning TOSICA on task: Protein Prediction with data: pretrained_processed_Dataset_B_TOSICA_TOSICA\n",
      "Evaluating TOSICA on dataset: Dataset_B\n",
      "\n",
      "Running pipeline for model: ScMMT\n",
      "Preprocessing dataset: Dataset_B for ScMMT\n",
      "Pretraining ScMMT with data: processed_Dataset_B_ScMMT\n",
      "Fine-tuning ScMMT on task: Protein Prediction with data: pretrained_processed_Dataset_B_ScMMT_ScMMT\n",
      "Evaluating ScMMT on dataset: Dataset_B\n",
      "Results saved to pipeline_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Mock implementations of models for demonstration purposes\n",
    "class Model:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def preprocess(self, dataset):\n",
    "        print(f\"Preprocessing dataset: {dataset} for {self.name}\")\n",
    "        return f\"processed_{dataset}_{self.name}\"\n",
    "\n",
    "    def pretrain(self, data):\n",
    "        print(f\"Pretraining {self.name} with data: {data}\")\n",
    "        return f\"pretrained_{data}_{self.name}\"\n",
    "\n",
    "    def fine_tune(self, data, task):\n",
    "        print(f\"Fine-tuning {self.name} on task: {task} with data: {data}\")\n",
    "        return f\"fine_tuned_{task}_{data}_{self.name}\"\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        print(f\"Evaluating {self.name} on dataset: {dataset}\")\n",
    "        # Mock evaluation metrics\n",
    "        return {\n",
    "            \"f1_score\": np.random.uniform(0.8, 1.0),\n",
    "            \"accuracy\": np.random.uniform(0.8, 1.0),\n",
    "        }\n",
    "\n",
    "# Instantiate models\n",
    "models = [\n",
    "    Model(\"TOSICA\"),\n",
    "    Model(\"ScMMT\"),\n",
    "    #Model(\"ScBERT\"),\n",
    "    #Model(\"XTrimoGene\"),\n",
    "    #Model(\"ScGPT\"),\n",
    "]\n",
    "\n",
    "def select_task():\n",
    "    tasks = [\"Cell Type Annotation\", \"Protein Prediction\"]\n",
    "    print(\"Available tasks:\")\n",
    "    for i, task in enumerate(tasks):\n",
    "        print(f\"{i + 1}. {task}\")\n",
    "    \n",
    "    choice = int(input(\"Select the task (1 or 2): \"))\n",
    "    return tasks[choice - 1]\n",
    "\n",
    "def select_dataset():\n",
    "    datasets = [\"Dataset_A\", \"Dataset_B\", \"Dataset_C\"]\n",
    "    print(\"Available datasets:\")\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print(f\"{i + 1}. {dataset}\")\n",
    "\n",
    "    choice = int(input(\"Select the dataset (1, 2, or 3): \"))\n",
    "    return datasets[choice - 1]\n",
    "\n",
    "def run_pipeline(task, dataset):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"\\nRunning pipeline for model: {model.name}\")\n",
    "\n",
    "        # Step 1: Preprocessing\n",
    "        processed_data = model.preprocess(dataset)\n",
    "\n",
    "        # Step 2: Pretraining\n",
    "        pretrained_data = model.pretrain(processed_data)\n",
    "\n",
    "        # Step 3: Fine-tuning\n",
    "        fine_tuned_model = model.fine_tune(pretrained_data, task)\n",
    "\n",
    "        # Step 4: Evaluation\n",
    "        metrics = model.evaluate(dataset)\n",
    "\n",
    "        # Collect results\n",
    "        results.append({\n",
    "            \"Dataset Name\": dataset,\n",
    "            \"Classifier Used\": task,\n",
    "            \"F1 Score\": metrics[\"f1_score\"],\n",
    "            \"Accuracy\": metrics[\"accuracy\"],\n",
    "            \"Model Name\": model.name,\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_results_to_csv(results, output_file=\"pipeline_results.csv\"):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # User selects task and dataset\n",
    "    selected_task = select_task()\n",
    "    selected_dataset = select_dataset()\n",
    "\n",
    "    # Run pipeline\n",
    "    pipeline_results = run_pipeline(selected_task, selected_dataset)\n",
    "\n",
    "    # Save results\n",
    "    save_results_to_csv(pipeline_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6ab1b-c3dd-4581-83d4-e6e2094ecc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
